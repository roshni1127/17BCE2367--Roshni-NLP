{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'snowballstemmer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-9b927c7b24ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msnowballstemmer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlanguages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'snowballstemmer' is not defined"
     ]
    }
   ],
   "source": [
    "len(snowballstemmer.languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(SnowballStemmer.languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'language'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-3834f5494027>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msnow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSnowballStemmer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlan\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLancasterStemmer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mreg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRegexpStemmer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'language'"
     ]
    }
   ],
   "source": [
    "snow = SnowballStemmer()\n",
    "pot = PorterStemmer()\n",
    "lan = LancasterStemmer()\n",
    "reg = RegexpStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'language'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-6fdde398434e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msnow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSnowballStemmer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlan\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLancasterStemmer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m reg = RegexpStemmer(\n\u001b[0;32m      5\u001b[0m '^un|^re|ing$|s$|ed$|er$',min=4)\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'language'"
     ]
    }
   ],
   "source": [
    "snow = SnowballStemmer()\n",
    "pot = PorterStemmer()\n",
    "lan = LancasterStemmer()\n",
    "reg = RegexpStemmer('^un|^re|ing$|s$|ed$|er$',min=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "snow = SnowballStemmer('english')\n",
    "pot = PorterStemmer()\n",
    "lan = LancasterStemmer()\n",
    "reg = RegexpStemmer('^un|^re|ing$|s$|ed$|er$',min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unwant\n"
     ]
    }
   ],
   "source": [
    "print(snow.stem('unwanted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unwant\n"
     ]
    }
   ],
   "source": [
    "print(pot.stem('unwanted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unw\n"
     ]
    }
   ],
   "source": [
    "print(lan.stem('unwanted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "want\n"
     ]
    }
   ],
   "source": [
    "print(reg.stem('unwanted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"In publishing and graphic design, Lorem ipsum is a placeholder text \n",
    "commonly used to demonstrate the visual form of a document or a typeface without \n",
    "relying on meaningful content. Lorem ipsum may be used before final copy is available, \n",
    "but it may also be used to temporarily replace copy in a process called greeking, \n",
    "which allows designers to consider form without the meaning of the text influencing the design.\n",
    "Lorem ipsum is typically a corrupted version of De finibus bonorum et malorum, \n",
    "a first-century BCE text by Cicero, with words altered, added, and removed to make it nonsensical, improper Latin.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In publish and graphic design, lorem ipsum is a placehold text \n",
      "commonli use to demonstr the visual form of a document or a typefac without \n",
      "reli on meaning content. lorem ipsum may be use befor final copi is available, \n",
      "but it may also be use to temporarili replac copi in a process call greeking, \n",
      "which allow design to consid form without the mean of the text influenc the design.\n",
      "lorem ipsum is typic a corrupt version of De finibu bonorum et malorum, \n",
      "a first-centuri bce text by cicero, with word altered, added, and remov to make it nonsensical, improp latin.\n"
     ]
    }
   ],
   "source": [
    "text = [pot.stem(txt) for txt in text.split(\" \")]\n",
    "print(\" \".join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_net = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "juice\n"
     ]
    }
   ],
   "source": [
    "print(word_net.lemmatize(\"juice\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mouse\n"
     ]
    }
   ],
   "source": [
    "print(word_net.lemmatize(\"mice\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gas\n"
     ]
    }
   ],
   "source": [
    "print(word_net.lemmatize(\"gases\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In\n",
      "publish\n",
      "and\n",
      "graphic\n",
      "design,\n",
      "lorem\n",
      "ipsum\n",
      "is\n",
      "a\n",
      "placehold\n",
      "text\n",
      "\n",
      "commonli\n",
      "use\n",
      "to\n",
      "demonstr\n",
      "the\n",
      "visual\n",
      "form\n",
      "of\n",
      "a\n",
      "document\n",
      "or\n",
      "a\n",
      "typefac\n",
      "without\n",
      "\n",
      "reli\n",
      "on\n",
      "meaning\n",
      "content.\n",
      "lorem\n",
      "ipsum\n",
      "may\n",
      "be\n",
      "use\n",
      "befor\n",
      "final\n",
      "copi\n",
      "is\n",
      "available,\n",
      "\n",
      "but\n",
      "it\n",
      "may\n",
      "also\n",
      "be\n",
      "use\n",
      "to\n",
      "temporarili\n",
      "replac\n",
      "copi\n",
      "in\n",
      "a\n",
      "process\n",
      "call\n",
      "greeking,\n",
      "\n",
      "which\n",
      "allow\n",
      "design\n",
      "to\n",
      "consid\n",
      "form\n",
      "without\n",
      "the\n",
      "mean\n",
      "of\n",
      "the\n",
      "text\n",
      "influenc\n",
      "the\n",
      "design.\n",
      "lorem\n",
      "ipsum\n",
      "is\n",
      "typic\n",
      "a\n",
      "corrupt\n",
      "version\n",
      "of\n",
      "De\n",
      "finibu\n",
      "bonorum\n",
      "et\n",
      "malorum,\n",
      "\n",
      "a\n",
      "first-centuri\n",
      "bce\n",
      "text\n",
      "by\n",
      "cicero,\n",
      "with\n",
      "word\n",
      "altered,\n",
      "added,\n",
      "and\n",
      "remov\n",
      "to\n",
      "make\n",
      "it\n",
      "nonsensical,\n",
      "improp\n",
      "latin.\n"
     ]
    }
   ],
   "source": [
    "for word in text:\n",
    "  print(word_net.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['added', 'allow', 'also', 'altered', 'and', 'available', 'bce', 'be', 'befor', 'bonorum', 'but', 'by', 'call', 'centuri', 'cicero', 'commonli', 'consid', 'content', 'copi', 'corrupt', 'de', 'demonstr', 'design', 'document', 'et', 'final', 'finibu', 'first', 'form', 'graphic', 'greeking', 'improp', 'in', 'influenc', 'ipsum', 'is', 'it', 'latin', 'lorem', 'make', 'malorum', 'may', 'mean', 'meaning', 'nonsensical', 'of', 'on', 'or', 'placehold', 'process', 'publish', 'reli', 'remov', 'replac', 'temporarili', 'text', 'the', 'to', 'typefac', 'typic', 'use', 'version', 'visual', 'which', 'with', 'without', 'word']\n"
     ]
    }
   ],
   "source": [
    "x = vectorizer.fit_transform(text)\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
